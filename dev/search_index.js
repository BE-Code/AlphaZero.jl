var documenterSearchIndex = {"docs":
[{"location":"alphazero/#AlphaZero-1","page":"AlphaZero","title":"AlphaZero","text":"","category":"section"},{"location":"alphazero/#","page":"AlphaZero","title":"AlphaZero","text":"CurrentModule = AlphaZero","category":"page"},{"location":"alphazero/#Modules-1","page":"AlphaZero","title":"Modules","text":"","category":"section"},{"location":"alphazero/#","page":"AlphaZero","title":"AlphaZero","text":"MCTS\nGameInterface\nNetwork","category":"page"},{"location":"alphazero/#AlphaZero.MCTS","page":"AlphaZero","title":"AlphaZero.MCTS","text":"A generic, standalone implementation of asynchronous Monte Carlo Tree Search. It can be used on any game that implements the GameInterface interface and with any external oracle.\n\n\n\n\n\n","category":"module"},{"location":"alphazero/#AlphaZero.GameInterface","page":"AlphaZero","title":"AlphaZero.GameInterface","text":"A generic interface for zero-sum, symmetric games.\n\n\n\n\n\n","category":"module"},{"location":"alphazero/#AlphaZero.Network","page":"AlphaZero","title":"AlphaZero.Network","text":"A generic, framework agnostic interface for neural networks.\n\n\n\n\n\n","category":"module"},{"location":"alphazero/#Training-Parameters-1","page":"AlphaZero","title":"Training Parameters","text":"","category":"section"},{"location":"alphazero/#","page":"AlphaZero","title":"AlphaZero","text":"Params\nSelfPlayParams\nLearningParams\nArenaParams\nMemAnalysisParams\nMctsParams","category":"page"},{"location":"alphazero/#AlphaZero.Params","page":"AlphaZero","title":"AlphaZero.Params","text":"Params\n\nParameters for the AlphaZero training process.\n\nParameter Type Default\nself_play SelfPlayParams -\nlearning LearningParams -\narena ArenaParams -\nmemory_analysis Union{Nothing, MemAnalysisParams} nothing\nnum_iters Int -\nmem_buffer_size PLSchedule{Int} -\nternary_rewards Bool false\n\nExplanation\n\nThe AlphaZero training process consists in num_iters iterations. Each iteration can be decomposed into a self-play phase and a learning phase.\n\nSet ternary_rewards to true if the rewards that are issued by the current game environment always belong to -1 0 1 so that the logging and profiling tools can take advantage of this property.\n\nAlphaGo Zero Parameters\n\nIn the original AlphaGo Zero paper:\n\nAbout 5 millions games of self-play are played across 200 iterations.\nThe memory buffer contains 500K games, which makes about 100M samples as an average game of Go lasts about 200 turns.\n\n\n\n\n\n","category":"type"},{"location":"alphazero/#AlphaZero.SelfPlayParams","page":"AlphaZero","title":"AlphaZero.SelfPlayParams","text":"SelfPlayParams\n\nParameters governing self-play.\n\nParameter Type Default\nmcts MctsParams -\nnum_games Int -\nreset_mcts_every Union{Int, Nothing} nothing\ngc_every Union{Int, Nothing} nothing\n\nExplanation\n\nThe gc_every field, when set, forces a full garbage collection and an emptying of the GPU memory pool periodically, the period being specified in terms of a fixed number of games.\nTo avoid running out of memory, the MCTS tree is reset every reset_mcts_every games (or never if nothing is passed).\n\nAlphaGo Zero Parameters\n\nIn the original AlphaGo Zero paper, num_games = 25_000 (5 millions games of self-play across 200 iterations).\n\n\n\n\n\n","category":"type"},{"location":"alphazero/#AlphaZero.LearningParams","page":"AlphaZero","title":"AlphaZero.LearningParams","text":"LearningParams\n\nParameters governing the learning phase of a training iteration, where the neural network is updated to fit the data in the memory buffer.\n\nParameter Type Default\nuse_gpu Bool true\ngc_every Union{Nothing, Int} nothing\nlearning_rate Float32 1f-3\nl2_regularization Float32 -\nnonvalidity_penalty Float32 1f0\nbatch_size Int -\nloss_computation_batch_size Int -\ncheckpoints Vector{Int} -\n\nDescription\n\nThe neural network gets to see the whole content of the memory buffer at each learning epoch, for maximum(checkpoints) epochs in total. After each epoch whose number is in checkpoints, the current network is evaluated against the best network so far (see ArenaParams).\n\nnonvalidity_penalty is the multiplicative constant of a loss term that  corresponds to the average probability weight that the network puts on  invalid actions.\nbatch_size is the batch size used for gradient descent.\nloss_computation_batch_size is the batch size that is used to compute the loss between each epochs.\n\nAlphaGo Zero Parameters\n\nIn the original AlphaGo Zero paper:\n\nThe batch size for gradient updates is 2048.\nThe L2 regularization parameter is set to 10^-4.\nCheckpoints are produced every 1000 training steps, which corresponds to seeing about 20% of the samples in the memory buffer: (1000  2048)  10^7   02.\nIt is unclear how many checkpoints are taken or how many training steps are performed in total.\n\n\n\n\n\n","category":"type"},{"location":"alphazero/#AlphaZero.ArenaParams","page":"AlphaZero","title":"AlphaZero.ArenaParams","text":"ArenaParams\n\nParameters that govern the evaluation process that compares a new neural network to the current best.\n\nParameter Type Default\nmcts MctsParams -\nnum_games Int -\nreset_mcts_every Union{Int, Nothing} nothing\nupdate_threshold Float64 -\n\nExplanation\n\nThe two competing networks are instantiated into two MCTS players of parameter mcts and then play num_games games, exchanging color after each game.\nThe new network is to replace the current best one if its average collected reward is greater or equal than update_threshold.\nTo avoid running out of memory, the MCTS trees of both player are reset every reset_mcts_every games (or never if nothing is passed).\n\nRemarks\n\nSee necessary_samples to make an informed choice for num_games.\n\nAlphaGo Zero Parameters\n\nIn the original AlphaGo Zero paper, 400 games are played to evaluate a network and the update_threshold parameter corresponds to a 55% win rate.\n\n\n\n\n\n","category":"type"},{"location":"alphazero/#AlphaZero.MemAnalysisParams","page":"AlphaZero","title":"AlphaZero.MemAnalysisParams","text":"MemAnalysisParams\n\nParameters governing the analysis of the memory buffer (for debugging and profiling purposes).\n\nParameter Type Default\nnum_game_stages Int -\n\nExplanation\n\nThe memory analysis consists in partitioning the memory buffer in num_game_stages parts of equal size, according to the number of remaining moves until the end of the game for each sample. Then, the quality of the predictions of the current neural network is evaluated on each subset (see Report.Memory).\n\nThis is useful to get an idea of how the neural network performance varies depending on the game stage (typically, good value estimates for endgame board positions are available earlier in the training process than good values for middlegame positions).\n\n\n\n\n\n","category":"type"},{"location":"alphazero/#AlphaZero.MctsParams","page":"AlphaZero","title":"AlphaZero.MctsParams","text":"Parameters of an MCTS player.\n\nParameter Type Default\nnum_workers Int 1\nuse_gpu Bool false\nnum_iters_per_turn Int -\ncpuct Float64 1.\ntemperature StepSchedule{Float64} StepSchedule(1.)\ndirichlet_noise_nα Float64 10.\ndirichlet_noise_ϵ Float64 0.\n\nExplanation\n\nAn MCTS player picks actions as follows. Given a game state, it launches num_iters_per_turn MCTS iterations that are executed asynchronously on num_workers workers, with UCT exploration constant cpuct.\n\nThen, an action is picked according to the distribution (1 - ϵ) π + ϵ η where\n\nπ_i  n_i^τ with n_i the number of time that the i^textth action was visited and τ the temperature parameter\nη  textDir(α) with α defined of the ratio of dirichlet_noise_nα by the number of available actions.\n\nRemarks\n\nIt is typical to use a high value of the temperature parameter τ during the first moves of a game to increase exploration and then switch to a small value. Therefore, temperature has type StepSchedule.\n\nAlphaGo Zero Parameters\n\nIn the original AlphaGo Zero paper:\n\nThe number of MCTS iterations per move is 1600, which corresponds to 0.4s of computation time.\nThe temperature is set to 1 for the 30 first moves and then to an infinitesimal value.\nThe ϵ parameter for the Dirichlet noise is set to 025 and η sim textDir(003). Given that there are 19  19 + 1 = 362 possible actions in Go, this gives us a value for dirichlet_noise_nα of 003  362 = 1086.\n\n\n\n\n\n","category":"type"},{"location":"alphazero/#Utilities-1","page":"AlphaZero","title":"Utilities","text":"","category":"section"},{"location":"alphazero/#","page":"AlphaZero","title":"AlphaZero","text":"necessary_samples","category":"page"},{"location":"alphazero/#AlphaZero.necessary_samples","page":"AlphaZero","title":"AlphaZero.necessary_samples","text":"necessary_samples(ϵ, β) = log(1 / β) / (2 * ϵ^2)\n\nCompute the number of times N that a random variable X sim textBer(p) has to be sampled so that if the empirical average of X is greather than 12 + ϵ, then p  12 with probability at least 1-β.\n\nThis bound is based on Hoeffding's inequality .\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#game_interface-1","page":"Game Interface","title":"Game Interface","text":"","category":"section"},{"location":"game_interface/#","page":"Game Interface","title":"Game Interface","text":"CurrentModule = AlphaZero.GameInterface","category":"page"},{"location":"game_interface/#","page":"Game Interface","title":"Game Interface","text":"The GameInterface module provides a generic interface for two-players, zero-sum, symmetric board games.","category":"page"},{"location":"game_interface/#","page":"Game Interface","title":"Game Interface","text":"Types, traits and constructors\nGame()\nGame(board)\nGame(board, white_playing)\nBase.copy(game)\nBoard(Game)\nAction(Game)\nGame functions\nwhite_playing(state)\nwhite_reward(state)\nboard(state)\nboard_symmetric(state)\navailable_actions(state)\nplay!(state, action)\nMachine learning interface\nvectorize_board(Game, board)\nnum_actions(Game)\naction_id(Game, action)\naction(Game, action_id)\nInterface for interactive tools\naction_string(Game, action)\nparse_action(Game, str)\nread_state(Game)\nprint_state(state)","category":"page"},{"location":"game_interface/#Types-1","page":"Game Interface","title":"Types","text":"","category":"section"},{"location":"game_interface/#","page":"Game Interface","title":"Game Interface","text":"AbstractGame\nBase.copy(::AbstractGame)\nBoard\nAction","category":"page"},{"location":"game_interface/#AlphaZero.GameInterface.AbstractGame","page":"Game Interface","title":"AlphaZero.GameInterface.AbstractGame","text":"AbstractGame\n\nAbstract base type for a game state.\n\nConstructors\n\nAny subtype Game must implement the following constructors:\n\nGame()\n\nReturn the initial state of the game.\n\nGame(board, white_playing=true)\n\nReturn the unique state specified by a board and a current player.\n\n\n\n\n\n","category":"type"},{"location":"game_interface/#Base.copy-Tuple{AlphaZero.GameInterface.AbstractGame}","page":"Game Interface","title":"Base.copy","text":"Base.copy(::AbstractGame)\n\nReturn a fresh copy of a game state.\n\n\n\n\n\n","category":"method"},{"location":"game_interface/#AlphaZero.GameInterface.Board","page":"Game Interface","title":"AlphaZero.GameInterface.Board","text":"Board(Game::Type{<:AbstractGame})\n\nReturn the board type corresponding to Game.\n\nBoard objects must be persistent or appear as such.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.Action","page":"Game Interface","title":"AlphaZero.GameInterface.Action","text":"Action(Game::Type{<:AbstractGame})\n\nReturn the action type corresponding to Game.\n\nActions must be \"symmetric\" in the following sense:\n\navailable_actions(s) ==\n  available_actions(Game(board_symmetric(s), !white_playing(s)))\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#Game-Functions-1","page":"Game Interface","title":"Game Functions","text":"","category":"section"},{"location":"game_interface/#","page":"Game Interface","title":"Game Interface","text":"white_playing\nwhite_reward\nboard\nboard_symmetric\navailable_actions\nplay!","category":"page"},{"location":"game_interface/#AlphaZero.GameInterface.white_playing","page":"Game Interface","title":"AlphaZero.GameInterface.white_playing","text":"white_playing(state::AbstractGame) :: Bool\n\nReturn true if white is to play and false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.white_reward","page":"Game Interface","title":"AlphaZero.GameInterface.white_reward","text":"white_reward(state::AbstractGame)\n\nReturn nothing if the game hasn't ended. Otherwise, return a reward for the white player as a number between -1 and 1.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.board","page":"Game Interface","title":"AlphaZero.GameInterface.board","text":"board(state::AbstractGame)\n\nReturn the game board.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.board_symmetric","page":"Game Interface","title":"AlphaZero.GameInterface.board_symmetric","text":"board_symmetric(state::AbstractGame)\n\nReturn the symmetric of the game board (where the roles of black and white are swapped).\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.available_actions","page":"Game Interface","title":"AlphaZero.GameInterface.available_actions","text":"available_actions(state::AbstractGame)\n\nReturn the vector of all available actions, which must be nonempty if isnothing(white_reward(state)).\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.play!","page":"Game Interface","title":"AlphaZero.GameInterface.play!","text":"play!(state::AbstractGame, action)\n\nUpdate the game state by making the current player perform action.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#Machine-Learning-Interface-1","page":"Game Interface","title":"Machine Learning Interface","text":"","category":"section"},{"location":"game_interface/#","page":"Game Interface","title":"Game Interface","text":"vectorize_board\nnum_actions\naction_id\naction","category":"page"},{"location":"game_interface/#AlphaZero.GameInterface.vectorize_board","page":"Game Interface","title":"AlphaZero.GameInterface.vectorize_board","text":"vectorize_board(::Type{<:AbstractGame}, board) :: Vector{Float32}\n\nReturn a vectorized representation of a board.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.num_actions","page":"Game Interface","title":"AlphaZero.GameInterface.num_actions","text":"num_actions(::Type{<:AbstractGame}) :: Int\n\nReturn the total number of actions for a game.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.action_id","page":"Game Interface","title":"AlphaZero.GameInterface.action_id","text":"action_id(G::Type{<:AbstractGame}, action) :: Int\n\nMap each action to a unique number in the range 1:num_actions(G).\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.action","page":"Game Interface","title":"AlphaZero.GameInterface.action","text":"action(::Type{<:AbstractGame}, Int)\n\nInverse function of action_id.\n\nMap an action identifier to an actual action.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#Interface-for-Interactive-Tools-1","page":"Game Interface","title":"Interface for Interactive Tools","text":"","category":"section"},{"location":"game_interface/#","page":"Game Interface","title":"Game Interface","text":"action_string\nparse_action\nread_state\nprint_state","category":"page"},{"location":"game_interface/#AlphaZero.GameInterface.action_string","page":"Game Interface","title":"AlphaZero.GameInterface.action_string","text":"action_string(::Type{<:AbstractGame}, action) :: String\n\nReturn a human-readable string representing the provided action.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.parse_action","page":"Game Interface","title":"AlphaZero.GameInterface.parse_action","text":"parse_action(::Type{<:AbstractGame}, str::String)\n\nReturn the action described by string str or nothing if str does not denote a valid action.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.read_state","page":"Game Interface","title":"AlphaZero.GameInterface.read_state","text":"read_state(::Type{G}) where G <: AbstractGame :: Union{G, Nothing}\n\nRead a state description from the standard input. Return the corresponding state or nothing in case of an invalid input.\n\n\n\n\n\n","category":"function"},{"location":"game_interface/#AlphaZero.GameInterface.print_state","page":"Game Interface","title":"AlphaZero.GameInterface.print_state","text":"print_state(state::AbstractGame)\n\nPrint a state on the standard output.\n\n\n\n\n\n","category":"function"},{"location":"misc/#Misc-1","page":"Misc","title":"Misc","text":"","category":"section"},{"location":"misc/#","page":"Misc","title":"Misc","text":"CurrentModule = AlphaZero","category":"page"},{"location":"misc/#","page":"Misc","title":"Misc","text":"Session\nSession(::Type{Game}, ::Type{Network}, params, netparams) where {Game, Network}\nSession(::Type{Game}, ::Type{Network}, dir) where {Game, Network}\nthink\npit","category":"page"},{"location":"misc/#AlphaZero.Session","page":"Misc","title":"AlphaZero.Session","text":"Session{Env}\n\nA basic user interface for AlphaZero environments.\n\n\n\n\n\n","category":"type"},{"location":"misc/#AlphaZero.Session-Union{Tuple{Network}, Tuple{Game}, Tuple{Type{Game},Type{Network},Any,Any}} where Network where Game","page":"Misc","title":"AlphaZero.Session","text":"Session(::Type{Game}, ::Type{Network}, params, netparams)\n\nCreate a new session.\n\n\n\n\n\n","category":"method"},{"location":"misc/#AlphaZero.think","page":"Misc","title":"AlphaZero.think","text":"think(::AbstractPlayer, state, turn_number::Int)\n\nReturn an (a, π) pair where a is the chosen action and π a probability distribution over available actions.\n\nNote that a does not have to be drawn from π.\n\n\n\n\n\n","category":"function"},{"location":"misc/#AlphaZero.pit","page":"Misc","title":"AlphaZero.pit","text":"pit(handler, baseline, contender, ngames)\n\nEvaluate two players against each other on a series of games.\n\nArguments\n\nhandler: this function is called after each simulated  game with two arguments: the game number i and the collected reward z  for the contender player\nbaseline, contender :: AbstractPlayer\nngames: number of games to play\n\nOptional keyword arguments\n\nreset_every: if set, players are reset every reset_every games\ncolor_policy: determine the color attribution policy, which is ALTERNATE_COLORS by default\n\n\n\n\n\n","category":"function"},{"location":"mcts/#MCTS-1","page":"MCTS","title":"MCTS","text":"","category":"section"},{"location":"mcts/#","page":"MCTS","title":"MCTS","text":"A generic, standalone implementation of asynchronous Monte Carlo Tree Search. It can be used on any game that implements the GameInterface interface and with any external oracle.","category":"page"},{"location":"mcts/#","page":"MCTS","title":"MCTS","text":"CurrentModule = AlphaZero.MCTS","category":"page"},{"location":"mcts/#Oracles-1","page":"MCTS","title":"Oracles","text":"","category":"section"},{"location":"mcts/#","page":"MCTS","title":"MCTS","text":"Oracle\nevaluate(::Oracle, board, actions)\nevaluate_batch(::Oracle, batch)\nRolloutOracle","category":"page"},{"location":"mcts/#AlphaZero.MCTS.Oracle","page":"MCTS","title":"AlphaZero.MCTS.Oracle","text":"MCTS.Oracle{Game}\n\nAbstract base type for an oracle. Oracles must implement MCTS.evaluate and MCTS.evaluate_batch.\n\n\n\n\n\n","category":"type"},{"location":"mcts/#AlphaZero.MCTS.evaluate-Tuple{AlphaZero.MCTS.Oracle,Any,Any}","page":"MCTS","title":"AlphaZero.MCTS.evaluate","text":"MCTS.evaluate(oracle::Oracle, board, available_actions)\n\nEvaluate a single board position (assuming white is playing).\n\nReturn a pair (P, V) where:\n\nP is a probability vector on available actions\nV is a scalar estimating the value or win probability for white.\n\n\n\n\n\n","category":"method"},{"location":"mcts/#AlphaZero.MCTS.evaluate_batch-Tuple{AlphaZero.MCTS.Oracle,Any}","page":"MCTS","title":"AlphaZero.MCTS.evaluate_batch","text":"MCTS.evaluate_batch(oracle::Oracle, batch)\n\nEvaluate a batch of board positions.\n\nExpect a vector of (board, available_actions) pairs and return a vector of (P, V) pairs.\n\nA default implementation is provided that calls MCTS.evaluate sequentially on each position.\n\n\n\n\n\n","category":"method"},{"location":"mcts/#AlphaZero.MCTS.RolloutOracle","page":"MCTS","title":"AlphaZero.MCTS.RolloutOracle","text":"MCTS.RolloutOracle{Game} <: MCTS.Oracle{Game}\n\nThis oracle estimates the value of a position by simulating a random game from it (a rollout). Moreover, it puts a uniform prior on available actions. Therefore, it can be used to implement the \"vanilla\" MCTS algorithm.\n\n\n\n\n\n","category":"type"},{"location":"mcts/#Environment-1","page":"MCTS","title":"Environment","text":"","category":"section"},{"location":"mcts/#","page":"MCTS","title":"MCTS","text":"Env\nexplore!\npolicy\nreset!","category":"page"},{"location":"mcts/#AlphaZero.MCTS.Env","page":"MCTS","title":"AlphaZero.MCTS.Env","text":"MCTS.Env{Game}(oracle; nworkers=1, fill_batches=false, cpuct=1.) where Game\n\nCreate and initialize an MCTS environment.\n\nArguments\n\noracle: external oracle\nnworkers: numbers of asynchronous workers (see below)\nfill_batches: if true, a constant batch size is enforced for evaluation  requests, by completing batches with dummy entries if necessary\ncpuct: exploration constant (in the UCT formula)\n\nAsynchronous MCTS\n\nIf nworkers == 1, MCTS is run in a synchronous fashion and the oracle is invoked through MCTS.evaluate.\nIf nworkers > 1, nworkers asynchronous workers are spawned, along with an additional task to serve board evaluation requests. Such requests are processed by batches of size nworkers using MCTS.evaluate_batch.\n\n\n\n\n\n","category":"type"},{"location":"mcts/#AlphaZero.MCTS.explore!","page":"MCTS","title":"AlphaZero.MCTS.explore!","text":"MCTS.explore!(env, state, nsims)\n\nRun nsims MCTS iterations from state.\n\nIn case there are multiple workers, nsims is rounded up to the nearest integer multiple of the number of workers.\n\n\n\n\n\n","category":"function"},{"location":"mcts/#AlphaZero.MCTS.policy","page":"MCTS","title":"AlphaZero.MCTS.policy","text":"MCTS.policy(env, state; τ=1.)\n\nReturn the recommended stochastic policy on state, with temperature parameter equal to τ.\n\nA call to this function must always be preceded by a call to MCTS.explore!.\n\n\n\n\n\n","category":"function"},{"location":"mcts/#AlphaZero.MCTS.reset!","page":"MCTS","title":"AlphaZero.MCTS.reset!","text":"MCTS.reset!(env)\n\nEmpty the MCTS tree.\n\n\n\n\n\n","category":"function"},{"location":"mcts/#Profiling-utilities-1","page":"MCTS","title":"Profiling utilities","text":"","category":"section"},{"location":"mcts/#","page":"MCTS","title":"MCTS","text":"inference_time_ratio\nmemory_footprint_per_node\napproximate_memory_footprint\naverage_exploration_depth","category":"page"},{"location":"mcts/#AlphaZero.MCTS.inference_time_ratio","page":"MCTS","title":"AlphaZero.MCTS.inference_time_ratio","text":"MCTS.inference_time_ratio(env)\n\nReturn the ratio of time spent by MCTS.explore! on position evaluation (through functions MCTS.evaluate or MCTS.evaluate_batch) since the environment's creation.\n\n\n\n\n\n","category":"function"},{"location":"mcts/#AlphaZero.MCTS.memory_footprint_per_node","page":"MCTS","title":"AlphaZero.MCTS.memory_footprint_per_node","text":"MCTS.memory_footprint_per_node(env)\n\nReturn an estimate of the memory footprint of a single node of the MCTS tree (in bytes).\n\n\n\n\n\n","category":"function"},{"location":"mcts/#AlphaZero.MCTS.approximate_memory_footprint","page":"MCTS","title":"AlphaZero.MCTS.approximate_memory_footprint","text":"MCTS.approximate_memory_footprint(env)\n\nReturn an estimate of the memory footprint of the MCTS tree (in bytes).\n\n\n\n\n\n","category":"function"},{"location":"mcts/#AlphaZero.MCTS.average_exploration_depth","page":"MCTS","title":"AlphaZero.MCTS.average_exploration_depth","text":"MCTS.average_exploration_depth(env)\n\nReturn the average number of nodes that are traversed during an MCTS iteration, not counting the root.\n\n\n\n\n\n","category":"function"},{"location":"#AlphaZero-1","page":"Home","title":"AlphaZero","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"A generic, simple and fast implementation of Deepmind's AlphaZero algorithm.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Supports both Flux and Knet\nRelies on a fast implementation of asynchronous Monte-Carlo Tree Search.\nProvides a comprehensive set of debugging and profiling tools.\nNew games can be added easily by implementing the game interface.","category":"page"},{"location":"network/#Network-Interface-1","page":"Network Interface","title":"Network Interface","text":"","category":"section"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"CurrentModule = AlphaZero.Network","category":"page"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"This module defines a generic, framework-agnostic interface for neural network oracles.","category":"page"},{"location":"network/#Mandatory-interface-1","page":"Network Interface","title":"Mandatory interface","text":"","category":"section"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"AbstractNetwork\nHyperParams\nhyperparams\nforward\ntrain!\nset_test_mode!\nparams\nregularized_params","category":"page"},{"location":"network/#AlphaZero.Network.AbstractNetwork","page":"Network Interface","title":"AlphaZero.Network.AbstractNetwork","text":"AbstractNetwork{Game} <: MCTS.Oracle{Game}\n\nAbstract base type for a neural network.\n\nConstructor\n\nAny subtype Network must implement the following constructor:\n\nNetwork(hyperparams)\n\nwhere the expected type of hyperparams is given by HyperParams(Network).\n\n\n\n\n\n","category":"type"},{"location":"network/#AlphaZero.Network.HyperParams","page":"Network Interface","title":"AlphaZero.Network.HyperParams","text":"HyperParams(::Type{<:AbstractNetwork})\n\nReturn the hyperparameter type associated with a given network type.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.hyperparams","page":"Network Interface","title":"AlphaZero.Network.hyperparams","text":"hyperparams(::AbstractNetwork)\n\nReturn the hyperparameters of a network.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.forward","page":"Network Interface","title":"AlphaZero.Network.forward","text":"forward(::AbstractNetwork, boards)\n\nCompute the forward pass of the network on a batch of inputs.\n\nExpect a Float32 tensor boards whose batch dimension is the last one.\n\nReturn a (P, V) triple where:\n\nP is a matrix of size (num_actions, batch_size). It is allowed to put weight on invalid actions (see evaluate).\nV is a row vector of size (1, batch_size)\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.train!","page":"Network Interface","title":"AlphaZero.Network.train!","text":"train!(::AbstractNetwork, loss, data, learning_rate)\n\nTrain a given network on data.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.set_test_mode!","page":"Network Interface","title":"AlphaZero.Network.set_test_mode!","text":"set_test_mode!(mode=true)\n\nPut a network in test mode or in training mode. This is relevant for networks featuring layers such as batch normalization layers.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.params","page":"Network Interface","title":"AlphaZero.Network.params","text":"params(::AbstractNetwork)\n\nReturn the collection of trainable parameters of the network.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.regularized_params","page":"Network Interface","title":"AlphaZero.Network.regularized_params","text":"regularized_params(::AbstractNetwork)\n\nReturn the collection of regularized parameters of a network. This usually excludes neuron's biases.\n\n\n\n\n\n","category":"function"},{"location":"network/#Conversion-and-copy-1","page":"Network Interface","title":"Conversion and copy","text":"","category":"section"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"Base.copy(::AbstractNetwork)\nto_gpu\nto_cpu\non_gpu\nconvert_input\nconvert_output","category":"page"},{"location":"network/#Base.copy-Tuple{AlphaZero.Network.AbstractNetwork}","page":"Network Interface","title":"Base.copy","text":"Base.copy(::AbstractNetwork)\n\nReturn a copy of the given network.\n\n\n\n\n\n","category":"method"},{"location":"network/#AlphaZero.Network.to_gpu","page":"Network Interface","title":"AlphaZero.Network.to_gpu","text":"to_gpu(::AbstractNetwork)\n\nReturn a copy of the given network that has been transferred to the GPU if one is available. Otherwise, return the given network untouched.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.to_cpu","page":"Network Interface","title":"AlphaZero.Network.to_cpu","text":"to_cpu(::AbstractNetwork)\n\nReturn a copy of the given network that has been transferred to the CPU or return the given network untouched if it is already on CPU.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.on_gpu","page":"Network Interface","title":"AlphaZero.Network.on_gpu","text":"on_gpu(::AbstractNetwork)\n\nTest if a network is located on GPU.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.convert_input","page":"Network Interface","title":"AlphaZero.Network.convert_input","text":"convert_input(::AbstractNetwork, input)\n\nConvert an array (or number) to the right format so that it can be used as an input by a given network.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.convert_output","page":"Network Interface","title":"AlphaZero.Network.convert_output","text":"convert_output(::AbstractNetwork, output)\n\nConvert an array (or number) produced by a neural network to a standard CPU array (or number) type.\n\n\n\n\n\n","category":"function"},{"location":"network/#Misc-1","page":"Network Interface","title":"Misc","text":"","category":"section"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"gc","category":"page"},{"location":"network/#AlphaZero.Network.gc","page":"Network Interface","title":"AlphaZero.Network.gc","text":"gc(::AbstractNetwork)\n\nPerform full garbage collection.\n\n\n\n\n\n","category":"function"},{"location":"network/#Derived-functions-1","page":"Network Interface","title":"Derived functions","text":"","category":"section"},{"location":"network/#Evaluation-function-1","page":"Network Interface","title":"Evaluation function","text":"","category":"section"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"evaluate","category":"page"},{"location":"network/#AlphaZero.Network.evaluate","page":"Network Interface","title":"AlphaZero.Network.evaluate","text":"evaluate(network::AbstractNetwork, boards, action_masks)\n\nEvaluate a batch of board positions. This function is a wrapper on forward that puts a zero weight on invalid actions.\n\nArguments\n\nboards is a tensor whose last dimension has size bach_size\naction_masks is a binary matrix of size (num_actions, batch_size)\n\nReturn\n\nReturn a (P, V, Pinv) triple where:\n\nP is a matrix of size (num_actions, batch_size).\nV is a row vector of size (1, batch_size).\nPinv is a row vector of size (1, batch_size)  that indicates the total probability weight put by the network  on invalid actions for each sample.\n\nAll tensors manipulated by this function have type Float32.\n\n\n\n\n\n","category":"function"},{"location":"network/#Oracle-interface-1","page":"Network Interface","title":"Oracle interface","text":"","category":"section"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"MCTS.evaluate(::AbstractNetwork, board, actions)\nMCTS.evaluate_batch(::AbstractNetwork, batch)","category":"page"},{"location":"network/#AlphaZero.MCTS.evaluate-Tuple{AlphaZero.Network.AbstractNetwork,Any,Any}","page":"Network Interface","title":"AlphaZero.MCTS.evaluate","text":"MCTS.evaluate(::AbstractNetwork, board, available_actions)\n\nEvaluate a single board position. See MCTS.evaluate(::MCTS.Oracle).\n\nwarning: Warning\nEvaluating a neural network on a single sample at a time is slow. When possible, use MCTS.evaluate_batch instead.\n\n\n\n\n\nMCTS.evaluate(oracle::Oracle, board, available_actions)\n\nEvaluate a single board position (assuming white is playing).\n\nReturn a pair (P, V) where:\n\nP is a probability vector on available actions\nV is a scalar estimating the value or win probability for white.\n\n\n\n\n\n","category":"method"},{"location":"network/#AlphaZero.MCTS.evaluate_batch-Tuple{AlphaZero.Network.AbstractNetwork,Any}","page":"Network Interface","title":"AlphaZero.MCTS.evaluate_batch","text":"MCTS.evaluate_batch(::AbstractNetwork, batch)\n\nEvaluate a batch of positions. See MCTS.evaluate_batch(::MCTS.Oracle).\n\n\n\n\n\nMCTS.evaluate_batch(oracle::Oracle, batch)\n\nEvaluate a batch of board positions.\n\nExpect a vector of (board, available_actions) pairs and return a vector of (P, V) pairs.\n\nA default implementation is provided that calls MCTS.evaluate sequentially on each position.\n\n\n\n\n\n","category":"method"},{"location":"network/#Misc-2","page":"Network Interface","title":"Misc","text":"","category":"section"},{"location":"network/#","page":"Network Interface","title":"Network Interface","text":"num_parameters\nnum_regularized_parameters\nmean_weight\ncopy(::AbstractNetwork)","category":"page"},{"location":"network/#AlphaZero.Network.num_parameters","page":"Network Interface","title":"AlphaZero.Network.num_parameters","text":"num_parameters(::AbstractNetwork)\n\nReturn the total number of parameters of a network.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.num_regularized_parameters","page":"Network Interface","title":"AlphaZero.Network.num_regularized_parameters","text":"num_regularized_parameters(::AbstractNetwork)\n\nReturn the total number of regularized parameters of a network.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.mean_weight","page":"Network Interface","title":"AlphaZero.Network.mean_weight","text":"mean_weight(::AbstractNetwork)\n\nReturn the mean absolute value of the regularized parameters of a network.\n\n\n\n\n\n","category":"function"},{"location":"network/#AlphaZero.Network.copy-Tuple{AlphaZero.Network.AbstractNetwork}","page":"Network Interface","title":"AlphaZero.Network.copy","text":"copy(::AbstractNetwork; on_gpu, test_mode)\n\nA copy function that also handles CPU/GPU transfers and test/train mode switches.\n\n\n\n\n\n","category":"method"}]
}
