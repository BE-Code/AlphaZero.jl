<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Learning to Play Connect Four · AlphaZero</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">AlphaZero</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../alphazero_intro/">Introduction to AlphaZero</a></li><li><a class="tocitem" href="../connect_four/">Training a Connect Four Agent</a></li></ul></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../../reference/params/">Training Parameters</a></li><li><a class="tocitem" href="../../reference/game_interface/">Game Interface</a></li><li><a class="tocitem" href="../../reference/mcts/">MCTS</a></li><li><a class="tocitem" href="../../reference/network/">Network Interface</a></li><li><a class="tocitem" href="../../reference/networks_library/">Networks Library</a></li><li><a class="tocitem" href="../../reference/player/">Players</a></li><li><a class="tocitem" href="../../reference/memory/">Memory Buffer</a></li><li><a class="tocitem" href="../../reference/environment/">Environment</a></li><li><a class="tocitem" href="../../reference/benchmark/">Benchmark</a></li><li><a class="tocitem" href="../../reference/reports/">Training Reports</a></li><li><a class="tocitem" href="../../reference/ui/">User Interface</a></li></ul></li><li><span class="tocitem">Contributing</span><ul><li><a class="tocitem" href="../../contributing/guide/">Contribution Guide</a></li><li><a class="tocitem" href="../../contributing/add_game/">Adding New Games</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Learning to Play Connect Four</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Learning to Play Connect Four</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/jonathan-laurent/AlphaZero.jl/blob/master/docs/src/tutorial/connect_four_old.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><p>The <code>scripts/profile/async_mcts.jl</code> script can be used to measure the resulting speedup for self-play data generation as a function of the number of asynchronous workers. We obtain the following on our hardware:</p><p><img src="../../assets/img/connect-four/async-profiling/mcts_speed.png" alt="Async speedup"/></p><p>This package provides a <em>generic</em>, <em>simple</em> and <em>fast</em> implementation of Deepmind&#39;s AlphaZero algorithm:</p><ul><li>The core algorithm is only 2,000 lines of pure, hackable Julia code.</li><li>Generic interfaces make it easy to add support for <a href="../../reference/game_interface/#game_interface-1">new games</a> or new <a href="../../reference/network/#network_interface-1">learning frameworks</a>.</li><li>Being between one and two orders of magnitude faster than its Python alternatives, this implementation enables learning decent players for nontrivial games on a standard desktop computer with a GPU.</li></ul><p><code>AlphaZero.jl</code> comes with <em>batteries included</em>. It features utilities for logging, profiling, benchmarking and model exploration that are ready to work with any new game.</p><pre><code class="language-none">bootstrap/
├── css/
│   ├── bootstrap.css
│   ├── bootstrap.min.css
│   ├── bootstrap-theme.css
│   └── bootstrap-theme.min.css
├── js/
│   ├── bootstrap.js
│   └── bootstrap.min.js
└── fonts/
    ├── glyphicons-halflings-regular.eot
    ├── glyphicons-halflings-regular.svg
    ├── glyphicons-halflings-regular.ttf
    └── glyphicons-halflings-regular.woff</code></pre><h1 id="Learning-to-Play-Connect-Four-1"><a class="docs-heading-anchor" href="#Learning-to-Play-Connect-Four-1">Learning to Play Connect Four</a><a class="docs-heading-anchor-permalink" href="#Learning-to-Play-Connect-Four-1" title="Permalink"></a></h1><p>In this section, we discuss how to use <code>AlphaZero.jl</code> to learn to play <em>Connect Four</em> without any form of supervision or prior knowledge. Although the game has been <a href="https://connect4.gamesolver.org/">solved</a> exactly with Alpha-beta pruning using domain-specific heuristics and optimizations, it is still a great challenge for reinforcement learning.<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup></p><p>Before you continue, we recommend that you read a high-level introduction such as <a href="https://web.stanford.edu/~surag/posts/alphazero.html">this one</a> if you are not already familiar with AlphaZero. In this tutorial, we are going to:</p><ol><li>Show you how to train a Connect Four agent on your own machine using the <code>AlphaZero.jl</code> package.</li><li>Give instructions to launch a training session on your machine</li><li>Discuss hyperparameters tuning</li><li>Analyze the results</li><li>Give an overview of <code>AlphaZero.jl</code> codebase.</li></ol><h2 id="Running-a-Training-Session-1"><a class="docs-heading-anchor" href="#Running-a-Training-Session-1">Running a Training Session</a><a class="docs-heading-anchor-permalink" href="#Running-a-Training-Session-1" title="Permalink"></a></h2><p>To replicate the experiment in this tutorial, we recommend having a CUDA compatible GPU with 6GB of memory or more. Each training iteration took about one hour and a half on a standard desktop computer with an Intel Core i5 9600K processor and an Nvidia RTX 2070 GPU.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>To get optimal performances, it is also recommended to use <code>AlphaZero.jl</code> with Julia 1.4 (nightly), which includes a <a href="https://github.com/JuliaLang/julia/pull/33448">critical feature</a> that enables <code>CuArrays</code> to force incremental GC collections.</p></div></div><p>In the following sections, we discuss some of those arguments in more details.</p><h2 id="Picking-Hyperparameters-1"><a class="docs-heading-anchor" href="#Picking-Hyperparameters-1">Picking Hyperparameters</a><a class="docs-heading-anchor-permalink" href="#Picking-Hyperparameters-1" title="Permalink"></a></h2><h3 id="Neural-Network-1"><a class="docs-heading-anchor" href="#Neural-Network-1">Neural Network</a><a class="docs-heading-anchor-permalink" href="#Neural-Network-1" title="Permalink"></a></h3><p>Here, we use the same architecture that is deployed in AlphaGo Zero, namely a two-headed convolutional resnet with batch normalization. However, our network is is smaller in size as it only features 7 blocks (instead of 20) and 128 convolutional filters per layer (instead of 256), resulting in about 2.5M parameters (instead of 90M).</p><h3 id="Training-Parameters-1"><a class="docs-heading-anchor" href="#Training-Parameters-1">Training Parameters</a><a class="docs-heading-anchor-permalink" href="#Training-Parameters-1" title="Permalink"></a></h3><p>Here, we simulate 5000 games of   self-play per iteration, using 400 MCTS iterations per move. For comparison,   the original AlphaGo Zero plays 25,000 games of self-play per iteration,   using 1600 MCTS iterations per move.</p><table><tr><th style="text-align: right">Implementation</th><th style="text-align: right">Games per iteration</th><th style="text-align: right">Moves per Game</th><th style="text-align: right">Sims per move</th><th style="text-align: right">Inference cost</th></tr><tr><td style="text-align: right">AlphaGo Zero</td><td style="text-align: right">25,000</td><td style="text-align: right">200</td><td style="text-align: right">1600</td><td style="text-align: right">x40</td></tr><tr><td style="text-align: right"><code>AlphaZero.jl</code></td><td style="text-align: right">5,000</td><td style="text-align: right">30</td><td style="text-align: right">400</td><td style="text-align: right">x1</td></tr><tr><td style="text-align: right">Python impl</td><td style="text-align: right">100</td><td style="text-align: right">30</td><td style="text-align: right">25</td><td style="text-align: right">x1</td></tr></table><h2 id="Hyperparameters-1"><a class="docs-heading-anchor" href="#Hyperparameters-1">Hyperparameters</a><a class="docs-heading-anchor-permalink" href="#Hyperparameters-1" title="Permalink"></a></h2><p>Depending on your available computing power, you may want to adjust some of these hyperparameters.</p><p>Virtual Loss https://blogs.oracle.com/developers/lessons-from-alpha-zero-part-5:-performance-optimization</p><p>A key aspect of making</p><p>A key feature of <code>AlphaZero.jl</code> that is responsible</p><p>performances comes from its asynchronous MCTS implementation, by enabling</p><p>A key aspect in speeding up MCTS is to enable several workers to explore the search tree asynchronously. This is a huge win even on a single machine, as it enables to perform neural-network inference on large batches rather than evaluating board positions separately, thereby maximizing the GPU utilization.</p><p>We benchmarked</p><p>In turn, half of this time is spent doing network inference to evaluate game positions.<sup class="footnote-reference"><a id="citeref-4" href="#footnote-4">[4]</a></sup></p><p>When using larger neural networks, the cost of inference quickly comes to   dominate, which is why DeepMind&#39;s AlphaGo Zero was trained on 64 GPUs.</p><p>Package overview:</p><ul><li><p>async mcts</p></li><li><p>Features: extensible memory (discussed in the tutorial)</p><ul><li>symmetries, growing memory, cyclic learning rates...</li></ul></li></ul><h4 id="Arena-results-1"><a class="docs-heading-anchor" href="#Arena-results-1">Arena results</a><a class="docs-heading-anchor-permalink" href="#Arena-results-1" title="Permalink"></a></h4><p><img src="../../assets/img/connect-four/plots/arena.png" alt="Arena results"/></p><h4 id="Exploration-depth-and-policy-entropy-1"><a class="docs-heading-anchor" href="#Exploration-depth-and-policy-entropy-1">Exploration depth and policy entropy</a><a class="docs-heading-anchor-permalink" href="#Exploration-depth-and-policy-entropy-1" title="Permalink"></a></h4><p><img src="../../assets/img/connect-four/plots/exploration_depth.png" alt="Exploration depth"/></p><h4 id="Loss-evolution-1"><a class="docs-heading-anchor" href="#Loss-evolution-1">Loss evolution</a><a class="docs-heading-anchor-permalink" href="#Loss-evolution-1" title="Permalink"></a></h4><p><img src="../../assets/img/connect-four/plots/loss.png" alt="Loss on full memory"/> <img src="../../assets/img/connect-four/plots/loss_per_stage.png" alt="Loss per game stage"/></p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>To the best of our knowledge, none of the many existing Python implementations of AlphaZero are able to learn a player that beats a minmax baseline that plans at depth 2 on a single desktop computer.</li><li class="footnote" id="footnote-4"><a class="tag is-link" href="#citeref-4">4</a></li></ul></section></article></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 26 March 2020 13:39">Thursday 26 March 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
